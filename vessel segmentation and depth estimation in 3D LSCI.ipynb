{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c88dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d95405",
   "metadata": {},
   "source": [
    "# Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af63dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset creation function\n",
    "def create_dataset_labels(path):\n",
    "    dirs = os.listdir(path+'Kt_sub')\n",
    "    classes = []\n",
    "    labels = []\n",
    "    masks = []\n",
    "    images = []\n",
    "    filenum = 0\n",
    "    for d in dirs:\n",
    "        classes.append(d)\n",
    "        files = os.listdir(path + 'Kt_sub/' + d)\n",
    "        filenum += len(files)\n",
    "        for n, f in tqdm(enumerate(files), total=len(files)):\n",
    "            label = float(f.split('.')[0].split('_')[1])/10000 # depth\n",
    "            labels.append(label)  # depth as the label\n",
    "            image = tf.keras.utils.load_img(path + '/Kt_sub/'+ d + '/'+ f)\n",
    "            image = tf.keras.utils.img_to_array(image)\n",
    "            images.append(image)\n",
    "            \n",
    "            mask = tf.keras.utils.load_img(path + '/mask/'+ d + '/'+ f,color_mode=\"grayscale\")\n",
    "            mask = tf.keras.utils.img_to_array(mask)\n",
    "#             mask = np.append(mask != 0, mask == 0, axis = 2)\n",
    "            mask = mask != 0\n",
    "            \n",
    "            masks.append(mask)\n",
    "            \n",
    "    print('Found '+str(filenum)+' files in '+ str(len(classes)) +' directories.')\n",
    "\n",
    "    images = tf.convert_to_tensor(images, dtype = tf.float32)\n",
    "    masks = tf.convert_to_tensor(masks, dtype = tf.bool)\n",
    "    labels = tf.convert_to_tensor(labels, dtype = tf.float32)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images,masks,labels))\n",
    "#     dataset = dataset.shuffle(buffer_size = 11200, reshuffle_each_iteration = True)\n",
    "#     dataset = dataset.batch(32)\n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b18724b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1680/1680 [00:02<00:00, 676.62it/s]\n",
      "100%|██████████| 1200/1200 [00:01<00:00, 673.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2880 files in 2 directories.\n",
      "<TensorSliceDataset shapes: ((128, 128, 3), (128, 128, 1), ()), types: (tf.float32, tf.bool, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "# create test dataset\n",
    "test_dataset = create_dataset_labels('test/')\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e5979",
   "metadata": {},
   "source": [
    "# UNet for vessel segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9449ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tversky function for DSC metrics\n",
    "from tensorflow.keras import backend as K \n",
    "def tversky(y_true, y_pred):\n",
    "    epsilon = 1e-5\n",
    "    smooth = 1\n",
    "    y_true = float(y_true)\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
    "    alpha = 0.5\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c9a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model 'UNet.h5'\n",
    "model1 = tf.keras.models.load_model('UNet.h5',custom_objects={'tversky':tversky})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b63be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 13s 59ms/step - loss: 0.0794 - tversky: 0.7403 - precision_2: 0.8122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07935435324907303, 0.7403233647346497, 0.8121510148048401]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model on test_dataset\n",
    "model1.evaluate(test_dataset.map(lambda x, y, z: (x, y)).batch(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a331fe",
   "metadata": {},
   "source": [
    "# ResNet for depth estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecf0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model 'ResNet.h5'\n",
    "model2 = tf.keras.models.load_model('ResNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3267c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 5s 25ms/step - loss: 3.6482e-04 - mae: 0.0135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00036482192808762193, 0.013457391411066055]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model on test_dataset\n",
    "model2.evaluate(test_dataset.map(lambda x, y, z: (x, z)).batch(32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-py3.9",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
